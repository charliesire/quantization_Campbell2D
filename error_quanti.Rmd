---
title: "Quantization error"
output: html_notebook
---

\newcommand{\Ecal}{\mathcal{Y}}
\newcommand{\Gamm}{\Gamma}
\newcommand{\norm}[1]{\lVert #1 \lVert_{\Ecal}}
\newcommand{\rep}{q_{\Gamm}}
\newcommand{\biais}{\nu}
\newcommand{\Ytrue}{{Y}}
\newcommand{\Ypred}{\hat{Y}}
\newcommand{\Ysimu}{Y_{simu}}
\newcommand{\Gammaref}{\Gamma^{\star}}
\newcommand{\Gammapred}{\hat\Gamma_{\star}}
\newcommand{\nerr}{n_{e}}

With the notebooks PMalgo_true.Rmd and PMalgo_pred.Rmd, we obtained two different sets of prototype maps : $\Gamm^{\star}$ obtained with the maps and $\hat{\Gamm}^{\star}$ with the predicted maps. 

Therefore, to evaluate the quality of the representive maps obtained in the predicted case, we compute the excess in quantization error due to the metamodel,
    $$\epsilon_\Gamma^{MM} = \frac{\hat{e}(\Gammapred)-\hat{e}(\Gammaref)}{\hat{e}(\Gammaref)}~,
$$ where $\hat{e}(\Gamm) = \left(\frac{1}{\nerr} \sum_{k = 1}^{\nerr} \norm{\Ytrue(\tilde{x}^k) - \rep(\Ytrue(\tilde{x}^k))}^2\frac{f_{X}(\tilde{x}^k)}{\biais(\tilde{x}^k)}\right)^{\frac{1}{2}}$ is an empirical quantization error, with $\nerr = 10^6$ here.
    

```{r}
source.all("GpOutput2D-main")
source.all("/FunQuant-0.1.3/R")
source("Campbell2D.R")
source("Campbell_utils.R")
```

```{r}
dim_map = c(64,64)

z1 = seq(-90,90,l=dim_map[1])
z2 = seq(-90,90,l=dim_map[2])
```

```{r}
set.seed(1234)
n=10^6
Xtilde = matrix(runif(n =5*n), ncol = 5)
Xtilde = cbind(Xtilde, sample(1:10,size = n, replace = TRUE) / 10)

unif = runif(n) 
Xtilde = cbind(Xtilde, (unif <= 8/13)*runif(n))

Xtilde = cbind(Xtilde, rep(-1,n))
Xtilde = transform_X(Xtilde)

```

```{r}
Xtilde_phy = ((Xtilde + 1)/6)[,1:7]
for(i in 1:5){
  Xtilde_phy[,i] = Xtilde_phy[,i] * (df_bornes[i,2]-df_bornes[i,1]) + df_bornes[i,1]
}
Xtilde_phy[,6] = Xtilde_phy[,6]*10

registerDoParallel(cores = 24)

density_ratio = foreach(batch = 1:20)%do%{
  print(batch)
  compute_density_ratio(fX, g, Xtilde_phy[((batch-1)*5*10^4+1):(batch*5*10^4),])}

  
```


We load the obtained representative maps 

```{r}
load("lloyd_res_true.RData")

load("lloyd_res_predict.RData")
gamma_pred = lloyd_res_predict$gamma
```


We compute $\hat{e}(\Gamm)$ for $\Gamm = \Gamm^{\star}$ and  $\Gamm = \hat{\Gamm}^{\star}$

```{r, results='hide'}

maps_true = lapply(1:20, function(it){
    print(it)
    Campbell2D(Xtilde[((it-1)*5*10^4+1):(it*5*10^4),], z1, z2)})

error_pred = quanti_error(outputs = maps_true, gamma = gamma_pred, density_ratio = density_ratio, batch = TRUE)



```
We now compute the excess in quantization error due to the metamodel.

```{r}
error_true = lloyd_res_true$all_errors
(error_pred - error_true)/error_true
```








