---
title: "Metamodel performance metrics"
output: html_notebook
---

\newcommand{\Ecal}{\mathcal{Y}}
\newcommand{\Esp}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\Espf}[1]{\mathbb{E}_{f_{X}}\left[#1\right]}
\newcommand{\Espbiais}[1]{\mathbb{E}_{\biais}\left[#1\right]}
\newcommand{\centro}{\gamma}
\newcommand{\Gamm}{\Gamma}
\newcommand{\norm}[1]{\lVert #1 \lVert_{\Ecal}}
\newcommand{\rep}{q_{\Gamm}}
\newcommand{\qgs}{q_{{\Gamm}^{\star}}}
\newcommand{\qgk}{q_{{\Gamm}^{[k]}}}
\newcommand{\scalprodE}[2]{\langle #1,#2\rangle_{\Ecal}}
\newcommand{\scalprod}[2]{\Esp{\scalprodE{#1}{#2}}}
\newcommand{\scalprodomega}[2]{\Esp{\scalprodE{#1}{#2}}}
\newcommand{\biais}{\nu}
\newcommand{\repo}{q^{0}_{\Gamm}}
\newcommand{\Xtildek}{\tilde{X}^{k}}
\newcommand{\Espprod}[1]{\mathbb{E}_{\Omega_{1}, \Omega_{2}}\left[#1\right]}
\newcommand{\var}{\mathbb{V}}
\newcommand{\clust}[2]{C^{#1}_{#2}}
\newcommand{\yinclust}[3]{#1 \in \clust{#2}{#3}}
\newcommand{\card}{\ell}
\newcommand{\campbell}{h}
\newcommand{\aff}{a}
\newcommand{\Jcal}{\mathcal{J}}
\newcommand{\Ytrue}{{Y}}
\newcommand{\Ypred}{\hat{Y}}
\newcommand{\Ysimu}{Y_{simu}}
\newcommand{\camprandom}{H}
\newcommand{\dime}{64}
\newcommand{\Gammaref}{\Gamma^{\star}}
\newcommand{\Gammapred}{\hat\Gamma^{\star}}
\newcommand{\Gammasimu}{\Gamma_{simu}}
\newcommand{\erreurproba}{\varepsilon}
\newcommand{\erreurprobarelative}{\epsilon_P^{MM}}
\newcommand{\erreurprobarelativecoastal}{\erreurprobarelative}
\newcommand{\nbgamma}{100}
\newcommand{\nbpilot}{v}
\newcommand{\ntrue}{n_{\mathrm{maps}}}
\newcommand{\npred}{n_{\mathrm{maps}}}
\newcommand{\nsimu}{n_{\mathrm{simu}}}
\newcommand{\Dspace}{\chi}
\newcommand{\supp}{{\mathrm{supp}}}
\newcommand{\thresh}{t}
\newcommand{\estim}{\hat{E}}
\newcommand{\nbsim}{m_{\mathrm{simu}}}
\newcommand{\ntrain}{n_{\mathrm{train}}}
\newcommand{\ntest}{n_{\mathrm{test}}}
\newcommand{\eqdef}{:=}
\newcommand{\Ypca}{Y^{\mathrm{pca}}}
\newcommand{\Yproj}{Y_{\mathrm{proj}}}
\newcommand{\nvar}{n_{v}}
\newcommand{\nerr}{n_{e}}

This notebook evaluates the precision of the metamodel on the evaluation of the probabilities, by computing the relative probability error.

## Introduction 

The method is to : 
 
  - Sample $(\tilde{X}^{(k)})_{k \in \{1,\dots,10^5\}}$ i.i.d of density function $\biais$
  - Compute $Y(\tilde{X}^{(k)})_{k \in \{1,\dots,10^5\}}$ the sample of real maps
  - Compute $\hat{Y}(\tilde{X}^{(k)})_{k \in \{1,\dots,10^5\}}$ the sample of predicted maps from 1300 training maps
  - Compute $(\Gamm^r)_{r \in \{1,\dots,100\}}$ from the $\Gamm^{\star}$ obtained by applying the Prototype Maps Algorithm with 10^6 maps (notebook lloyd_true.Rmd). A random change between 0 and $20\%$ is apply to $\Gamm^{\star}$
  - Compute $\forall r \in \{1,\dots,100\}, \erreurprobarelative(n,\Gamm^{r},j) = \frac{\mid  \hat{P}_{n}(\Gamm^{r},j,\Ytrue) - \hat{P}_{n}(\Gamm^{r},j,\Ypred) \mid}{\hat{P}_{n}(\Gamm^{r},j,\Ytrue)}$ with $n= 10^5$
  
 
  

```{r}
load("NewFitting_Charlie_v090821.RData")

source.all("GpOutput2D-main/GpOutput2D/R")
source("Campbell2D.R")
source("Campbell_utils.R")
```



```{r}
dim_map = c(64,64)

z1 = seq(-90,90,l=dim_map[1])
z2 = seq(-90,90,l=dim_map[2])

```

## Get biased sample 

We sample $(\tilde{X}^{(k)})_{k \in \{1,\dots,10^5\}}$ i.i.d of density function $\biais$

```{r}
set.seed(1234)
n=10^5
Xtilde = matrix(runif(n =5*n), ncol = 5)
Xtilde = cbind(Xtilde, sample(1:10,size = n, replace = TRUE) / 10) 

unif = runif(n) 
Xtilde = cbind(Xtilde, (unif <= 8/13)*runif(n))

Xtilde = cbind(Xtilde, rep(-1,n))
Xtilde = transform_X(Xtilde)
X_training = Xtilde[1:1300,]
Y_training = Campbell2D(X_training,z1,z2)
```

## Compute the weights 

We compute $\left(\frac{f_{X}(\tilde{X}^{(k)})}{\biais(\tilde{X}^{(k)})}\right){_{k \in \{1,\dots,10^5\}}}$

```{r}
Xtilde_phy = ((Xtilde + 1)/6)[,1:7]
for(i in 1:5){
  Xtilde_phy[,i] = Xtilde_phy[,i] * (df_bornes[i,2]-df_bornes[i,1]) + df_bornes[i,1]
}
Xtilde_phy[,6] = Xtilde_phy[,6]*10

registerDoParallel(cores = 24)

densite_vec = densite_ratio_full_vec(Xtilde_phy)

```

## Get $\Gamm^{\star}$ from the notebook PMalgo_true.Rmd

```{r}
load("lloyd_res_true.RData")
gamma_star = lloyd_res_true$gamma #the prototype maps obtained with the true maps



```


## Tuning of the hyperparameters

We will perform a cross validation step to tune the hyperparameters $\tilde{K}$ and $n_{pc}$ of the FPCA. 

For all $\tilde{K}$ and $n_{pc}$, we compute : $\forall j \in {1,\dots, 5},\erreurprobarelative(10^4,\Gamm^{\star},j)$. 

And then we select the pair $\tilde{K}, n_{pc}$ that minimizes the maximum of these 5 relative error.

```
ncoeff_vec=  seq(1000,4000, 500) #we will test these values of ncoeff_vec

model_cv = list() 
for(i in 1:length(ncoeff_vec)){ #for each ncoeff
  set.seed(1)
  print(i)
  ncoeff = ncoeff_vec[i]
  fp = Fpca2d.Wavelets(Y_training, wf = "d4", boundary = "periodic", J = 1, ncoeff = ncoeff, rank = 6) #we apply fpca with Ktilde = ncoeff and npc = 6
  model_cv[[i]] = km_Fpca2d(formula = ~1, design = data.frame(x = X_training)[,1:7], response = fp, covtype = "matern5_2",control = list(trace = 0), nugget.estim = TRUE) ##we fit a GP on each of these 6 axis

}
  
```


```
npc_vec = 2:6 #These are the testes values for npc

grid_cv = expand.grid(ncoeff_vec, npc_vec) ##we will try all the combinations of npc, Ktilde
n_cv = 10^4 
df_cv_pred = data.frame()
iter = 1
maps_true_cv = Campbell2D(Xtilde[1301:(n_cv+1300),],z1,z2) #we compute 10^4 maps


numeros_true_cv = get_numeros(maps_true_cv, gamma_star) #we associate each map to its voronoi cell

proba_true_cv = get_probas(numeros = numeros_true_cv, densite_vec = densite_vec[1301:(1300+n_cv)]) #we compute the probabilities


df_cv_pred = data.frame()
for(i in 1:nrow(grid_cv)){ #for each pair Ktilde, npc
  print(i)
  ncoeff = grid_cv[i,1] 
  npc = grid_cv[i,2]
  indice_coeff = which(ncoeff_vec == ncoeff)
  fp = Fpca2d.Wavelets(Y_training, wf = "d4", boundary = "periodic", J = 1, ncoeff = ncoeff, rank = npc) ##We apply fpca with the values of the hyperparameters
  model = lapply(1:npc, function(k){model_cv[[indice_coeff]][[k]]}) #we select the npc first GP metamodel computed previously 
  map_metamodel_cv = predict.km_Fpca2d(object = model, newdata = data.frame(Xtilde[1301:(n_cv+1300),1:7]), type = "UK", compute = FALSE, checkNames = FALSE, fpca = fp)$mean #we predict 10^4 maps
  numeros_pred_cv = get_numeros(map_metamodel_cv, gamma_star) #we compute the voronoi cell associated to each map

  proba_pred_cv = get_probas(numeros = numeros_pred_cv, densite_vec = densite_vec[1301:(1300+n_cv)]) #We compute the predicted probabilities
  err_rel = abs(proba_true_cv - proba_pred_cv)/proba_true_cv #Compute the empirical relative errors
  df_cv_pred = rbind(df_cv_pred, err_rel)     

}

grid_cv[which.min(apply(df_cv_pred, 1, max)),] ##print the pair of hyperparameters minimizing the maximum of these empirical relative errors
```

## Creation of the family $(\Gamma_{r})_{r \in \{1,\dots,100\}}$

```{r}
set.seed(2)
gamma_it_list = list()
for(it in 1:100){
  gamma_it_list[[it]] = lapply(1:5, function(i){gamma_star[[i]]*matrix(runif(64^2,0.8,1.2), ncol = 64, nrow = 64)})
}
```

## True maps

Compute $Y(\tilde{X}^{(k)})_{k \in \{1,\dots,10^5\}}$ the sample of real maps

```{r}
maps_true = Campbell2D(Xtilde,z1,z2)

```

Associate each of these $10^5$ maps to their voronoi cell for each $\Gamm^{r}$

```{r,  results='hide'}

numeros_true = lapply(1:length(gamma_it_list),function(it){print(it)
  get_numeros(maps_true[,,1:10^5], gamma_it_list[[it]])})


```

Compute the probabilities for each $\Gamm^{r}$

```{r}
proba_true = lapply(1:length(gamma_it_list), function(it){get_probas(numeros = numeros_true[[it]], densite_vec = densite_vec[1:10^5])})

rm(maps_true)
```

## Predicted maps

Predict the $10^5$ maps with the tuned hyperparameters 

```{r}
registerDoParallel(cores = 24)

set.seed(1)
fp = Fpca2d.Wavelets(Y_training, wf = "d4", boundary = "periodic", J = 1, ncoeff = 2000, rank = 6) #fpca

  
model = km_Fpca2d(formula = ~1, design = data.frame(x = X_training)[,1:7], response = fp, covtype = "matern5_2",control = list(trace = 0)) # fit GP on each axis



```

```{r}
set.seed(1234)

map_metamodel = predict.km_Fpca2d(object = model, newdata = data.frame(Xtilde[,1:7]), type = "UK", compute = FALSE, checkNames = FALSE)$mean #predict the maps

map_metamodel[,,1:1300] = Y_training

```

Compute the predicted voronoi cells
```{r,  results='hide'}

numeros_predict = lapply(1:length(gamma_it_list),function(it){print(it)
  get_numeros(map_metamodel[,,1:10^5], gamma_it_list[[it]])})


```

And now the predicted probabilities

```{r}
proba_predict = lapply(1:length(gamma_it_list), function(it){get_probas(numeros = numeros_predict[[it]], densite_vec = densite_vec[1:10^5])})


```

## Distribution of the errors 

Compute the relative probability error and display the distribution 


```{r, fig.height = 5, fig.width = 5}
relative_error = data.frame(relative_error = abs(unlist(proba_predict) - unlist(proba_true))/unlist(proba_true))

boxplot(relative_error, col = "darkolivegreen2", ylab = "Proba. relative metamodel error", log = "y",  cex.lab=1.3, cex.axis = 1.3)

```





