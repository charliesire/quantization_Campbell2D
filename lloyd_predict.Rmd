---
title: "Lloyd with predicted maps"
output: html_notebook
---

\newcommand{\Ecal}{\mathcal{Y}}
\newcommand{\Esp}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\Espf}[1]{\mathbb{E}_{f_{X}}\left[#1\right]}
\newcommand{\Espbiais}[1]{\mathbb{E}_{\biais}\left[#1\right]}
\newcommand{\centro}{\gamma}
\newcommand{\Gamm}{\Gamma}
\newcommand{\norm}[1]{\lVert #1 \lVert_{\Ecal}}
\newcommand{\rep}{q_{\Gamm}}
\newcommand{\qgs}{q_{{\Gamm}^{\star}}}
\newcommand{\qgk}{q_{{\Gamm}^{[k]}}}
\newcommand{\scalprodE}[2]{\langle #1,#2\rangle_{\Ecal}}
\newcommand{\scalprod}[2]{\Esp{\scalprodE{#1}{#2}}}
\newcommand{\scalprodomega}[2]{\Esp{\scalprodE{#1}{#2}}}
\newcommand{\biais}{\nu}
\newcommand{\repo}{q^{0}_{\Gamm}}
\newcommand{\Xtildek}{\tilde{X}^{k}}
\newcommand{\Espprod}[1]{\mathbb{E}_{\Omega_{1}, \Omega_{2}}\left[#1\right]}
\newcommand{\var}{\mathbb{V}}
\newcommand{\clust}[2]{C^{#1}_{#2}}
\newcommand{\yinclust}[3]{#1 \in \clust{#2}{#3}}
\newcommand{\card}{\ell}
\newcommand{\campbell}{h}
\newcommand{\aff}{a}
\newcommand{\Jcal}{\mathcal{J}}
\newcommand{\Ytrue}{{Y}}
\newcommand{\Ypred}{\hat{Y}}
\newcommand{\Ysimu}{Y_{simu}}
\newcommand{\camprandom}{H}
\newcommand{\dime}{64}
\newcommand{\Gammaref}{\Gamma^{\star}}
\newcommand{\Gammapred}{\hat\Gamma_{\star}}
\newcommand{\Gammasimu}{\Gamma_{simu}}
\newcommand{\erreurproba}{\varepsilon}
\newcommand{\erreurprobarelative}{\delta}
\newcommand{\erreurprobarelativecoastal}{\erreurprobarelative}
\newcommand{\nbgamma}{100}
\newcommand{\nbpilot}{v}
\newcommand{\ntrue}{n_{t}}
\newcommand{\npred}{n_{pred}}
\newcommand{\nsimu}{n_{\mathrm{simu}}}
\newcommand{\Dspace}{\chi}
\newcommand{\supp}{{\mathrm{supp}}}
\newcommand{\thresh}{t}
\newcommand{\estim}{\hat{E}}
\newcommand{\nbsim}{m_{\mathrm{simu}}}
\newcommand{\ntrain}{n_{\mathrm{train}}}
\newcommand{\ntest}{n_{\mathrm{test}}}
\newcommand{\eqdef}{:=}
\newcommand{\Ypca}{Y^{\mathrm{pca}}}
\newcommand{\Yproj}{Y_{\mathrm{proj}}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand\dsone{\mathds{1}}
\newcommand{\Ecal}{\mathcal{E}}
\newcommand{\Esp}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\centro}{\gamma}
\newcommand{\Gamm}{\Gamma}
\newcommand{\norm}[1]{\lVert #1 \lVert_{\mathcal{E}}}
\newcommand{\rep}{q_{\Gamm}}
\newcommand{\qgs}{q_{{\Gamm}^{\star}}}
\newcommand{\qgk}{q_{{\Gamm}^{[k]}}}
\newcommand{\scalprodE}[2]{\langle #1,#2\rangle_{\mathcal{E}}}
\newcommand{\scalprod}[2]{\Esp{\scalprodE{#1}{#2}}}
\newcommand{\repo}{q^{0}_{\Gamm}}
\newcommand{\Xtildek}{\tilde{X}^{k}}

Here we will perform the Lloyd's algorithm exactly as in the lloyd_true.Rmd notebook, but with predicted maps instead of the true campbell maps.

We use the hyperparameters tuned in the notebook perf_probas.Rmd with the cross validation : $\tilde{K} = 2000$ and $n_{pc} = 6$



```{r}
load("NewFitting_Charlie_v090821.RData")

source.all("GpOutput2D-main")
source("Campbell2D.R")
source("Campbell_utils.R")
```


```{r}
dim_map = c(64,64)

z1 = seq(-90,90,l=dim_map[1])
z2 = seq(-90,90,l=dim_map[2])

```

We sample $(\tilde{X}^{(k)})_{k \in \{1,\dots,10^6\}}$ i.i.d of density function $\biais = \biais_{1}\times\dots\times \biais_{7}$ with $\forall i \in \{1,\dots,5\}, \biais_{i} = \mathbb{1}_{[0,1]}$, $\biais_{6} = \frac{1}{10}\sum_{k=1}^{10}\delta_{\frac{1}{10}}$ and $\biais_{7} = \frac{5}{13}  \delta_{0} + (\frac{8}{13})\mathbb{1}_{]0,1]}$.

Then we perform a linear transformation of $(\tilde{X}^{(k)})_{k \in \{1,\dots,10^6\}}$ so that $\tilde{X}^{(k)} \in [-1,5]^7$.

We also compute $(\tilde{X}_{phy}^{(k)})_{k \in \{1,\dots,10^6\}}$ that is a linear transformation of $\tilde{X}$ in the support of $f_{X}$, so that we compute the weights $\left(\frac{f_{X}(\tilde{X}^{(k)})}{\biais(\tilde{X}^{(k)})}\right){_{k \in \{1,\dots,10^6\}}}$.

```{r}
set.seed(1234)
n=10^6
Xtilde = matrix(runif(n =5*n), ncol = 5)
Xtilde = cbind(Xtilde, sample(1:10,size = n, replace = TRUE) / 10)

unif = runif(n) 
Xtilde = cbind(Xtilde, (unif <= 8/13)*runif(n))

Xtilde = cbind(Xtilde, rep(-1,n))
Xtilde = transform_X(Xtilde)
X_training = Xtilde[1:1300,]
X_test = Xtilde[1301:n,]
Y_training = Campbell2D(X_training,z1,z2)
```



```{r}
Xtilde_phy = ((Xtilde + 1)/6)[,1:7]
for(i in 1:5){
  Xtilde_phy[,i] = Xtilde_phy[,i] * (df_bornes[i,2]-df_bornes[i,1]) + df_bornes[i,1]
}
Xtilde_phy[,6] = Xtilde_phy[,6]*10

registerDoParallel(cores = 24)

densite_vec = foreach(it = 1:10, .combine = "c") %dopar% {
  densite_ratio_full_vec(Xtilde_phy[((it-1)*10^5 + 1):(it*10^5),])
}


```


```{r}

set.seed(1)
fp = Fpca2d.Wavelets(Y_training, wf = "d4", boundary = "periodic", J = 1, ncoeff = 2000, rank = 6)

  
model = km_Fpca2d(formula = ~1, design = data.frame(x = X_training)[,1:7], response = fp, covtype = "matern5_2",control = list(trace = 0))



```

maps_metamodel is a list of 10 elements : each element is a batch of $10^5$ maps

```{r}
set.seed(1234)

map_metamodel = lapply(1:10, function(it){
  predict.km_Fpca2d(object = model, newdata = data.frame(Xtilde[((it-1)*10^5+1):(it*10^5),1:7]), type = "UK", compute = FALSE, checkNames = FALSE)$mean
})

map_metamodel[[1]][,,1:1300] = Y_training

```

We take the same $\Gamm_{0}$ as the one used in the lloyd_true.Rmd notebook, as the objective here is to compare the method with the true maps to the method with the predicted maps.

```{r}
load("gamma_0.RData")
```

## Adapted Lloyd algorithm

```{r}
lloyd_campbell = function(gamma, maps, densite_vec){
  n = dim(maps[[1]])[3]*length(maps) #nb of maps
  card = length(gamma) #nb of prototype maps
    for (i in 1:100){ #budget
      print(i)
      gamma_new <<- list() #Initilize the new prototype maps
      proba_cluster = c()
      numeros = Vectorize(function(it){get_numeros(maps[[it]],gamma)})(1:length(maps)) #Associate each map to its Voronoi cell
      for (j in 1:card){ #for each Voronoi cell
        estim_1 = rep(0, dim_map[1]*dim_map[2]) ## Compute estim_1*n 
        for(batch in 1:length(maps)){ ## For each batch of maps_true
          estim_1 = estim_1 + apply(t(matrix(maps[[batch]][,,numeros[,batch] == j],nrow = dim_map[1]*dim_map[2], ncol = sum(numeros[,batch] == j)))*densite_vec[((batch-1)*10^5 + 1):(batch*10^5)][numeros[,batch] == j],2, sum) ## Sum the Y(X)f/nu of the cell
        }
        estim_2 = sum(densite_vec[as.numeric(numeros) == j]) ## Sum the f/nu(X) of the cell
        centroid = estim_1/estim_2 ## Compute the ratio of the two estimators
        proba_cluster = c(proba_cluster, estim_2/n) ## Store the estimated probability mass of the cell

        gamma_new[[j]] <<- matrix(centroid, ncol = ncol(gamma[[j]])) ## store the centroid in gamma_new
  
      }
      check_fixed_point = 0 #check_fixed_point checks if gamma_new is different the previous gamma
      for (m in 1:card){
        check_fixed_point = check_fixed_point + distance_gamma(gamma_new[[m]], gamma)$dist
      
      }
      if (check_fixed_point == 0){break} #if they are equal, then break
      water_volume = c()  #we will sort the prototype maps by increasing water volume
      for (k in 1:card){water_volume = c(water_volume, sum(gamma_new[[k]]))}
      for(k in 1:card){gamma[[rank(water_volume)[k]]] = gamma_new[[k]]}
      }
    return(list(gamma = gamma, iterations = i, numeros = numeros, proba = proba_cluster))  # return the optimal gamma, the number of iterations, the cells of each map and the probabilities associated to the cells
}
```



```{r,  results='hide'}
lloyd_res_predict = lloyd_campbell(gamma, map_metamodel, densite_vec)

```

```{r}

for(i in 1:5){print(plot_map(lloyd_res_predict$gamma[[i]]))}
```



